{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XExON3xaODPi"
   },
   "source": [
    "# Text Embeddings\n",
    "\n",
    "Before you start working on this notebook, have a look to this [blogpost](https://towardsdatascience.com/bow-to-bert-2695cdb19787).\n",
    "\n",
    "The general goal in NLP is to learn from text data by transforming it into a vector-like format while keeping the semantic meaning of each word and its context. This vector-like format is what we will call embeddings.\n",
    "\n",
    "Now, depending on the goal of our project, we may aim to have embeddings for each word in our text or for representing the whole text (i.e. all the text from each of the restaurant reviews).\n",
    "\n",
    "Coming back to the machine learning protocol, embeddings are vectors that will be used to feed a model (i.e. classifier, linear model, clustering, neural network, etc) to train it and make predictions. Depending on the data science problem that we face we will use one or another model, we will deep dive into different use cases in the next days.\n",
    "\n",
    "In this notebook we are going to focus on producing embeddings that describe the whole text, each of the restaurant reviews. We are going to start from the traditional and more intuitive methods:\n",
    "* Bag of Words (BOW)\n",
    "* TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYtZEzPxODPt"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.corpus import wordnet\n",
    "from datetime import datetime\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6u2F43S7ODP8"
   },
   "outputs": [],
   "source": [
    "def visualize_wordcloud_dict_frequencies(dict_freqs, title, relative_scaling=0.5, max_words=100,\n",
    "                                background_color='black'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    wordcloud = WordCloud(width=900, height=500, max_words=max_words, relative_scaling=relative_scaling,\n",
    "                          normalize_plurals=False, background_color=background_color).generate_from_frequencies(\n",
    "        dict_freqs)\n",
    "    plt.title(title)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5UwEC6dPpxx"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__o7wEhKODQC"
   },
   "outputs": [],
   "source": [
    "path_to_file = '../../datasets/Class_Exercises_for_Students/Ex 6.2. ratings.csv'\n",
    "data = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U03tBGNPODQH"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpXtKfAyU7r1"
   },
   "outputs": [],
   "source": [
    "samples = data['review'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCmt6l7WODQm"
   },
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtH6hcKkODQn"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "matrix = CountVectorizer(max_features=100)\n",
    "X = matrix.fit_transform(samples).toarray()\n",
    "\n",
    "end = time.time()\n",
    "print(\"It took {} sec to fit and transform all documents.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swrtw_zjODRJ"
   },
   "outputs": [],
   "source": [
    "# Build the column names dictionary -> ordered dataframe\n",
    "bow_dict = matrix.vocabulary_\n",
    "df_baw_voc = pd.DataFrame({'column_name': list(bow_dict.keys()), 'column_index': list(bow_dict.values())})\n",
    "df_baw_voc = df_baw_voc.sort_values(by='column_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhgVbwT1ODRV"
   },
   "outputs": [],
   "source": [
    "# Build the matrix dataframe with the right columns\n",
    "df_X = pd.DataFrame(X)\n",
    "df_X.columns = df_baw_voc['column_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yX4wwAsFODRa"
   },
   "outputs": [],
   "source": [
    "title=\"Bag of Words all reviews\"\n",
    "d_freq_bow = df_X.sum().to_dict()\n",
    "visualize_wordcloud_dict_frequencies(d_freq_bow, title, relative_scaling=0.5, max_words=1000,\n",
    "                                background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BY8gYKboZezE"
   },
   "outputs": [],
   "source": [
    "# Exercise 1. You are transforming 1319968 reviews into vectors of 100 dimensions in 42s.\n",
    "# Do you think that Sklearn is doing this operation column or row based? Compare with\n",
    "# the time that it took the tokenization of reviews through a row based iterative process\n",
    "# in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCGAtxQZal9C"
   },
   "outputs": [],
   "source": [
    "# Exercise 2. Do you see in the wordcloud words that you would consider as stopwords? Go to\n",
    "# the sklearn CountVectorizer class documentation and find out how to fix this problem.\n",
    "# Rerun the cells and have a look to the wordcloud, which words have highest frequency now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmfN44AcODRC"
   },
   "outputs": [],
   "source": [
    "# Exercise 3. Check out the RAM memory bar while you transform the reviews into\n",
    "# vectors of bags of words. The parameter \"max_features\" will determine the number of\n",
    "# words that will define each of the reviews in your dataset (the dimensions). Play around with it\n",
    "# visualizing the wordcloud from each setup and argument which number is the optimal\n",
    "# from your perspective and for which goal do you think it is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMuYroqtODRh"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30BFm9KRODRi"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=0.1)\n",
    "X_tfidf = vectorizer.fit_transform(samples)\n",
    "\n",
    "end = time.time()\n",
    "print(\"It took {} sec to fit and transform all documents.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gv8nZmFSODRq"
   },
   "outputs": [],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJ1uXUTaODR2"
   },
   "outputs": [],
   "source": [
    "# Build the column names dictionary -> ordered dataframe\n",
    "tfidf_dict = vectorizer.vocabulary_\n",
    "df_tf_idf_voc = pd.DataFrame({'column_name': list(tfidf_dict.keys()), 'column_index': list(tfidf_dict.values())})\n",
    "df_tf_idf_voc = df_tf_idf_voc.sort_values(by='column_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uy97RudwODR8"
   },
   "outputs": [],
   "source": [
    "# Build the matrix dataframe with the right columns\n",
    "df_X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "df_X_tfidf.columns = df_tf_idf_voc['column_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GANx82UOODSL"
   },
   "outputs": [],
   "source": [
    "title=\"TF-IDF vector representation of all reviews\"\n",
    "d_freq_tfidf = df_X_tfidf.sum().to_dict()\n",
    "visualize_wordcloud_dict_frequencies(d_freq_tfidf, title, relative_scaling=0.5, max_words=500,\n",
    "                                background_color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttswefwwcySy"
   },
   "outputs": [],
   "source": [
    "# Exercise 4. As in the previous section, find out how to exclude stopwords and play around\n",
    "# to find the best model hyperparameters \"max_df\" and \"min_df\". Based on which criteria did you\n",
    "# choose those ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdqDsgi0ODSY"
   },
   "source": [
    "## Cosine similarity between reviews\n",
    "\n",
    "Most likely you realized during the exercises that the optimization of the embeddings may be perform with a specific goal (i.e. capture words related to sentiment to predict reviews rating).\n",
    "\n",
    "In order to evaluate the type of semantic information captured in the embeddings generated, we can use pairwise distance metric (similarity metric) in order to know which reviews are more closed based on the encoded knowledge by each setup.\n",
    "\n",
    "For high dimensional vectors we will use cosine distance or cosine similarity metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDEf-6fAODSZ"
   },
   "source": [
    "#### Get vectors of products with reviews containing food words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XstYPK5xODSa"
   },
   "outputs": [],
   "source": [
    "# We want to know whether reviews that are similar to one with high frequency on\n",
    "# the word \"great\" are also positive reviews and the other way around. Let's use \n",
    "# review number \"1162740\" as our reference.\n",
    "df_X_tfidf['great'].sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1573997226084,
     "user": {
      "displayName": "Celsa Diaz Tejada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRLKE2xPO_1xlStu23aIHVTzMcWQTqXhfesNrew=s64",
      "userId": "05772264038088628288"
     },
     "user_tz": -60
    },
    "id": "fsPPMZWFiqGe",
    "outputId": "38a273d0-2653-4c03-e8c6-191cca8b97d6"
   },
   "outputs": [],
   "source": [
    "#We'll take one review that contains \"great\"\n",
    "samples.iloc[1162740]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSMizsMzODSe"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original df to avoid problems with different dimensionality\n",
    "df_X_tfidf_ = df_X_tfidf.copy()\n",
    "\n",
    "# Have a look to the Sklearn method \"cosine_similarity\" to know how to calculate cosine\n",
    "# similarity. It requires two matrices. Here we're computing the cosine similarity of \n",
    "# the review 1162740 against all the other ones\n",
    "reference_review_matrix = np.expand_dims(np.array(df_X_tfidf_.iloc[1162740].values), axis=0)\n",
    "distances_to_reference_review = cosine_similarity(reference_review_matrix, X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create a dataframe with the results\n",
    "sim_df = pd.DataFrame(distances_to_reference_review).transpose()\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most similar\n",
    "similar = sim_df.nlargest(10,[0])\n",
    "for i in similar.index:\n",
    "    print (samples.iloc[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on? Check for duplicates and repeat the process to get\n",
    "# most similar reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F31psnW4ODS6"
   },
   "outputs": [],
   "source": [
    "# Get the most dis-similar\n",
    "dissimilar = sim_df.nsmallest(10,[0])\n",
    "for i in dissimilar.index:\n",
    "    print (samples.iloc[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE1B7qO0ODTL"
   },
   "outputs": [],
   "source": [
    "# Exercise 5. Is this the separation of reviews that you expected to split by customer\n",
    "# satisfaction? If not, play around with the two methods for text embeddings, its hyper parameters\n",
    "# and the code until you feel familiar with the whole process. Now try to find the best embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7Hi6MUoODTO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhstbC_aODTZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Text Embeddings 1 - BOW & TFIDF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
